# Running Meeting Minutes
## Date: 3/6/24

### Attending
* Brandon Dave
* Calvin Greenewald
* Stacie Severyn

### Agenda
* Walls/Restrictions/Knowledge Gaps

### Action
* TODO
    * Assigned to:
    * Due by:
    

### Additional Notes
* Example text

## Date: 02/22/24

### Attending
* Brandon Dave
* Calvin Greenewald
* Stacie Severyn

### Agenda
* Discussion of problem statement
* Solidify yes/no with going with Cogan and Lingwei's Preliminary research pushing for NeSy 2024 deadline (April 5, 12)
* Planning on Spring Break: Cogan out of office Sunday-to-Sunday, but remotely reachable


### Action
* Research knowledge gaps
    * Assigned to: Calvin, Stacie
    * Due by: 3/6
* Coordinate a meeting with Cogan and Lingwei post-spring break to present concrete ideas
    * Assigned to: Everyone
    * Due by: 3/5

### Additional Notes
* Datasets have been provided on Discord
* Next meeting: 3/6
* 3pm Lingwei <> Calvin meeting will solidify preliminary research decision

## Date: 02/20/24

### Attending
* Brandon Dave
* Calvin Greenewald
* Stacie Severyn

### Agenda
* Next meeting 1-2pm Thursday
* Discussion of findings from annotated biblio

### Action
* During Lit Review, figure out AA methodologies
    * Assigned to: Everyone
    * Due by: 2/22

* Continue lit review
    * Assigned to: Everyone
    * Due by: 2/23
    
### Additional Notes
* Using LaTeX for any paper writing
* Plan around Spring Break, maybe virtual meeting looping in faculty members on overall total ideas gathered

## Date: 02/13/24

### Attending
* Brandon Dave
* Calvin Greenewald
* Stacie Severyn

### Agenda
* Discuss Lit Review stage

### Action
* Complete reading of 3-5 annotated bibliograph (including Cogan suggested)
    * Assigned to: Everyone
    * Due by: 2/20
    

### Additional Notes
* Public KBs can be found from one of the appendices of Brandon's paper when we get that far
* The actual output of KB falsified facts are not necessarily the purpose, but analyzing the performance changes in KGs after training on AA data points
* Use found paper references for hints on connecting relevance
* Narrative: 
    * From Cogan email:
        * > **Declan O'Sullivan** is a part of two of these. Maybe it's worth also digging further into his work more extensively. Anyway, these papers were relatively quick to consume.
        * > Anyway, there is research that says that **dilution of true facts with adversarial or false facts can obscure true facts within the dataset (kg)**. So perhaps one way of moving forward is â€“ **what is the threshold or ratio to which true vs. decoy becomes problematic in link prediction**. After that, the steps become more nebulous. 
            * What mechanisms are there to protect against poisoning? 
            * Does choosing a training set more carefully (or differently) matter? 
            * To what extent does the incorporation of false negative triples as couterfactuals during training negatively impact performance? 
            * Is there a way to make the KGE system "doubt itself" so to speak?
